**RAG（Retrieval-Augmented Generation）** + **Embedding 向量检索** 做笔记向量搜索

## ** rag(Retrieval-Augmented Generation)**

* **定位**：解决 **知识缺失问题**。    适合做：  FAQ 问答、文档助手、学习笔记检索
* **流程**：
  1. 用户提问
  2. 系统在 **向量知识库** 中检索相似文档
  3. 将 **检索结果 + 用户问题** 拼接到 Prompt
  4. 交给 LLM 生成答案
* **特点**：
  * 核心是 **检索增强**
  * 逻辑简单（基本就是 Query → 向量检索 → 拼 Prompt → LLM）

## **MCP (Model Context Protocol)**

* **定位**：一种 **标准化协议**，让 AI 模型能 **安全地访问外部工具/资源**。
* **机制**：
  * 工具（API、数据库、搜索引擎等）以 **标准格式注册**
  * AI 通过 MCP 协议调用这些工具
  * 统一了 **调用方式** 和 **安全边界**
* **特点**：
  * 类似 “AI 的驱动程序协议”
  * 和 RAG 不冲突，反而可以结合：RAG 做知识增强，MCP 做工具调用

👉 适合做：AI Agent 工具注册、跨系统集成

---

## 3. **AI Agent**

* **定位**：一种 **能自主决策的 AI 实体**，不仅回答问题，还能 **选择工具、规划步骤、调用 API**。
* **特点**：
  * 有自然语言交互
  * 具备 **工具调用能力**（通过 MCP 或自定义注册）
  * 能够进行 **推理 + 行动**（ReAct/Chain-of-Thought 规划）
* **工作流程例子**：
  1. 用户问：*"帮我查一下我上周在 GitHub 上提交的 PR 数量"*
  2. AI Agent 思考：需要用 GitHub API
  3. Agent 自主调用注册的 `github.getPullRequests` 工具
  4. 拿到数据后总结并回复

👉 适合做：个人助理、企业助手（CRM、ERP AI）、自动化执行任务

a2a:不同agent相互调用

Function Calling（函数调用）

Function Calling 是 OpenAI 新 API 提供的一种功能：你告诉模型“有一个函数，它的参数长这样”，然后模型会自动生成函数调用所需的参数，而不是随意写文字。

JSON Schema  一种**描述 JSON 结构和约束规则的规范**

作用：定义数据结构

JSON Schema 是一种标准化方式，用于描述 JSON 数据的结构、字段类型、是否必填等规则。

模型可以根据这个 Schema 来生成数据，但仅仅是“遵循规则生成 JSON”，并不涉及调用函数或自动解析。

特点：

描述数据格式和类型（object、array、string、integer…）。

可以规定字段必填、可选、默认值等。

模型输出的 JSON 符合 schema，但模型仍然可能输出额外文本，如果没有 Function Calling 的约束。

向量为什么用float[]存储？？？


| 类型         | 优点                     | 缺点                           |
| ------------ | ------------------------ | ------------------------------ |
| float[]      | 内存小，计算快，足够精度 | 精度有限                       |
| double[]     | 精度更高，计算仍快       | 内存占用翻倍                   |
| BigDecimal[] | 超高精度                 | 内存大，计算慢，不适合向量检索 |

1. 笔记向量化  场景特点：笔记修改频繁    选 1.3           1.1 MQ 消息堆积 CPU/GPU 调用频繁 1.2 占满线程池，没有恢复机制  1.3 有延迟，适合笔记修改频繁，结合增量修改：task 表只存最后一次修改的 noteId，需要控制批量大小和并行度

1.1 单条笔记向量化：创建，修改，删除笔记内容时，写task表，发送mq（携带noteid），接收后去调用笔记模块提供的RPC接口，得到最新数据（llw），调用向量化模型，更新笔记向量表，更新task表    还有定时任务扫描task表重新发送mq   优点：异步，实时，失败可恢复，幂等和一致性可控  缺点：性能开销大，高并发时 MQ 消息堆积，CPU/GPU 被频繁调用 （最后修改笔记，mq发送在笔记表落库后，最终一致性）

1.2 创建，修改，删除笔记内容时，异步线程池，调用aiservice,调用向量化模型，更新笔记向量表表

1.3 定时把修改的笔记id存起来，分布式定时任务每60分钟做向量化，向量化并成功落库后再删除对应的笔记id ，再做一个定时（每天全量扫描笔记表与笔记向量表的版本号，更新（可以用登录的用户来减少笔记扫描范围）） 优点：异步批量处理，性能高，高并发笔记修改不会瞬间打爆 MQ 或向量化模型，异步处理，失败可恢复    缺点： OOM,处理超时  需要异步 / 并行控制，控制批量大小  （有很多不一致，相对一致，保持一个相对较新的状态）

1.4 在写笔记表时，对内容分词，全部写入笔记向量表（向量先空着），再异步对内容做向量化  缺点：模型接口（如 OpenAI API）压力大，容易触发限流或超时  OOM 或线程池饱和  写内容需要需要批量删除再批量插入 不同领域聚合  （强一致性）

又一个问题：1.1~1.3有个问题    从 **读取笔记数据库 → 向量化 → 向量落库**，这几个步骤 **不可放在同一个事务里**，因为向量化模型可能耗时较长，数据库事务不可能一直占着，这就引入了 **潜在的数据不一致问题**

方法：

1. 只在创建笔记时生成最初文本的向量，更新笔记需要手动  向量表内容与笔记表可能不一致  **适用场景**：笔记内容基本不会修改，或检索对实时性要求不高
2. 笔记表加版本号 / 更新时间戳

向量检索：搜索内容向量化，与向量库里的笔记向量做相似度搜索，合并得到对应笔记的排序（设置相似度阈值，结合业务逻辑做二次过滤）

**预处理**

* 去除 Markdown 标记、HTML 标签。
* 按 **分片（chunking）** 切分长文（比如每 500\~1000 个 token 一片）。
* 每片记录笔记 ID、片段序号。

1.1 mq的顺序性？  note\_embedding 队列    **推荐 / 向量化 / 异步分析** → 允许延迟，最终覆盖最新数据即可

**所有相关的需要有序的在同一个队列** → 消息天然是有序的（FIFO）

**

* **单队列 (FIFO)**：RabbitMQ、Kafka (单 partition)、RocketMQ (单队列) 都是 FIFO → **消息入队顺序 = 出队顺序**
* **分区/多队列**：Kafka 多分区、RabbitMQ 多队列时，**不同队列之间不保证顺序**
* **单消费者**：完全按发送顺序消费，顺序严格保证，一次消费一个  单机可以，分布式不行，也要做最终一致性
* **多个消费者**：

  * 不同消息可能被不同线程或进程同时处理
  * 如果消费后操作（如写数据库）是异步或并发执行，最终落库顺序可能乱

**解决方法**：

“时间戳控制”，时间不大不修改

最终覆盖（Last Write Wins, LWW）

* 或者 **幂等 + 版本号** 控制，即允许乱序处理也能保证最终一致性
* 补偿机制（Compensation）
* 状态机约束

ai笔记复习卡片生成 用ResponseFormat 确保输出结果是想要的格式
